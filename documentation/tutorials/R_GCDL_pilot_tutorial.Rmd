```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "assets/R_GCDL_pilot_tutorial/"
)
```

<!--
---
title: GeoCDL Pilot Tutorial
layout: single
author: Heather Savoy
author_profile: true
header:
  overlay_color: "444444"
  overlay_image: /assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg
---
--> 

**Last Update:** 09 March 2022 <br />
**Download RMarkdown**: [R_GCDL_pilot_tutorial.Rmd](https://geospatial.101workbook.org/tutorials/R_GCDL_pilot_tutorial.Rmd)

<!-- ToDo: would be great to have an R binder badge here -->

## Overview

This tutorial covers the SCINet Geospatial Common Data Library (GeoCDL), a community project from the [Geospatial Working Group](https://scinet.usda.gov/working-groups/geospatial) to reduce the time and effort to access commonly used spatial datasets. 

![GeoCDL basic architecture. This tutorial covers how to access the central Web API with R. ](../basic_architecture.png){width=100%}

This example covers the pilot features implemented in the GeoCDL web API v0.1.0. The tutorial assumes you are either on CERES or a local machine connected to the [SCINet VPN](https://scinet.usda.gov/guide/vpn). For more details on the development of the web API, see [https://github.com/USDA-SCINet/geocdl/](https://github.com/USDA-SCINet/geocdl/) (request access from brian.stucky@usda.gov).

To learn more about the `R` package `rgcdl` in development to streamline these requests, see [https://github.com/USDA-SCINet/rgcdl/](https://github.com/USDA-SCINet/rgcdl/)



*Language:* `R`

*Primary Libraries/Packages:*

| Name | Description | Link |
|:--|:--|:--|
| raster | Geographic Data Analysis and Modeling | https://cran.r-project.org/web/packages/raster/index.html |
| sf | Simple Features for R | https://cran.r-project.org/web/packages/sf/index.html |
| jsonlite | jsonlite: A Simple and Robust JSON Parser and Generator for R | https://cran.r-project.org/web/packages/jsonlite/index.html |

## Nomenclature

* *Web API:* < Description >
* *Data access protocol:* < Description >
* *Coordinate Reference System (CRS):* < Description >
* *EPSG code:* 

## Data Details

* Data: MODIS NDVI Data, Smoothed and Gap-filled, for the Conterminous US: 2000-2015
* Link: [https://doi.org/10.3334/ORNLDAAC/1299](https://doi.org/10.3334/ORNLDAAC/1299)
* Other Details: This dataset is acquired via the GeoCDL. It is 70.8 GB, but the GeoCDL leverages data access protocols to access the dataset remotely from online servers, use server-side functions for basic spatial and temporal filtering, and download the user's requested subset of data. 


* Repository: < Link to Repository >
* Data: < Name of Dataset >
* Link: < Link to the dataset >
* Other Details: < other >

## Tutorial Steps

* Specify desired data - Define the spatiotemporal scope of the user request:
  * Dataset and variables
  * Temporal coverage 
  * Spatial coverage, spatial resolution, and CRS
* Build GeoCDL query - desc….
* Download requested data - desc….
* Visualize results - desc...

## Step 0: Import Libraries/Packages

```{r libraries, message=FALSE, warning=FALSE}
library(raster)
library(sf)
library(jsonlite)
library(tidyverse)
library(ggthemes)
```

## Step 1: Point to Web API

The GeoCDL Web API lives on a CERES service node that can be accessed by ... It has multiple endpoints, each of which will be showcased below. 

```{r step1}
# Web API address
gcdl_url <- 'http://127.0.0.1:8000/'

# Subset polygon endpoint: for requesting gridded data within an area
polygon_ep <- 'subset_polygon'

# Point subset endpoint: for requesting point data
points_ep <- 'subset_points'

```


## Step 2: Specify area and date range of interest 

We will focus on the USDA-ARS Jornada Experimental Range in southern New Mexico. We will showcase returning both gridded data overlapping the site and point data at experiment locations within it. To specify these areas, we will read in a shapefile of the site boundary and a shapefile of experiment locations. These shapefiles are in UTM 13N CRS. The package `sf` is used to read in the shapefiles and extract the necessary information for GeoCDL. 

First, we will retrieve the bounding box around the site with the function `st_bbox`. Currently, GeoCDL v0.1.0 only supports bounding boxes for areas of interest [not true anymore! show both? at leasst text general polygon]. The expected format is `xmin,ymax,xmax,ymin` [still true?], so we will rearrange `st_bbox`'s returned value into that order and collapse the vector into a string.

Next, we will extract the CRS information so we can tell GeoCDL the CRS of our area of interest. GeoCDL v0.1.0 only accepts EPSG codes [not true anymore!]. The output of `st_crs` contains this information. 

For this example, we will request all data from 2000-2010. *Elaborate here on formatting dates after Mar 9 meeting discussing date support*

```{r step2, warning=FALSE}
# Read in Jornada boundary shapefile and format bounding box for GeoCDL
jer_bounds <- st_read('assets/R_GCDL_pilot_tutorial/Boundary.shp')
jer_bbox <- st_bbox(jer_bounds) # returns c(xmin,ymin,xmax,ymax)
bbox_str <- paste0("(",jer_bbox[1],",",jer_bbox[4],"),(",jer_bbox[3],",",jer_bbox[2],")")

# Read in Jornada NPP locations shapefile and format coordinates for GeoCDL
jer_pts <- st_read('assets/R_GCDL_pilot_tutorial/NPP_sites.shp') 
pts_str <- jer_pts  %>% 
  st_coordinates() %>% 
  as_tibble() %>% 
  mutate_all(~round(.,2)) %>% 
  rowwise() %>% 
  mutate(coord = paste0("(",X,",",Y,")")) %>% 
  ungroup() %>% 
  pull(coord) %>% 
  paste0(collapse = ",")

# Extract EPSG code (same for both shapefiles)
jer_crs <- paste0('EPSG:',
                  st_crs(jer_bounds)$input)


# Date range for NDVI
start_date <- '2008-07-01' 
end_date <- '2008-08-31'  

# Month range for PRISM
start_month <- '2008-07'
end_month <- '2008-08'

# To comment on mixed date grain issue:
# For me, one format I'd want is to be able to request monthly PRISM 
# and sparse daily NDVI at the same time by
# 1. monthly format meaning all NDVI dates in those months, or
#     '2008-04' and '2008-07' would be interpreted as '2008-04-01' and '2008-07-31' for NDVI.
# 2. daily format meaning all PRISM months covered by those dates, 
#     '2008-04-15' and '2008-07-15' would be interpreted as '2008-04' and '2008-07' for PRISM.
# Either have this in web API, or have packages submit request per date grain


```

## Step 3: Select datasets and their variables

The GeoCDL can be queried to return the currently available datasets and their metadata. We will be using the MODIS NDVI Data, Smoothed and Gap-filled, for the Conterminous US: 2000-2015 data product which is stored under the ID *MODIS_NDVI*.
We can see from its metadata that this dataset has a ... CRS, different from our area of interest objects. The GeoCDL will accommodate the discrepancy. The metadata also indicates that there is just one variable: NDVI. We will format the dataset and variable list in the expected format of `DATASET_ID:VARNAME[,VARNAME...]`.

```{r step3}
# 1, Query the GeoCDL to list all datasets
all_datasets <- fromJSON(url(paste0(gcdl_url,'list_datasets'))) %>%
  as_tibble()
all_datasets
my_ds <- 'MODIS_NDVI'

# 2. View a dataset's metadata
fromJSON(url(paste0(gcdl_url,'ds_info?id=',my_ds)))
my_vars <- c('NDVI')

# 3. Format dataset and variable
dv_str <- paste0(my_ds,':',paste(my_vars,collapse = ','))

```

## Step 4: Build and submit request to GeoCDL

Now that we've defined and formatted the pieces of the request, we can merge them into a request URL to communicate with the GeoCDL. The `download.file` function accepts this kind of URL and downloads the returned file to the specified path. GeoCDL returns a zipped folder of the requested data plus a metadata file. 

```{r step4a}
#  Prepare polygon query
q_str <- paste0(gcdl_url,
                polygon_ep,
                '?',
                paste0(
                  'date_start=',start_date,
                  '&date_end=',end_date,
                  '&crs=',jer_crs,
                  '&datasets=',URLencode(dv_str, reserved = TRUE),
                  '&clip=',URLencode(bbox_str, reserved = TRUE)))  

outpath <- 'assets/tmp'
out_z <- paste0(outpath,'.zip')

start_clock <- Sys.time()
download.file(q_str, out_z)
end_clock <- Sys.time()

# How long did the download take?
end_clock - start_clock

unzip(out_z, exdir = paste0(outpath,"/"))
```



## Step 5: Read in and visualize results from GeoCDL

```{r step5, out.width="100%"}
# Create a raster stack of returned GeoTIFFs
NDVI_2008 <- list.files(outpath,'NDVI[[:graph:]]*.tif',full.names = TRUE) %>%
  stack() 

NDVI_2008 %>%
  as.data.frame(xy = TRUE) %>%
  pivot_longer(contains('NDVI'),
               names_to = c(NA,NA,'var','date'),
               names_sep = c('[_]'),
               values_to = 'NDVI') %>%
  ggplot() +
  geom_raster(aes(x,y,fill=NDVI)) +
  geom_sf(fill = NA,
          color = 'red',
          data=jer_bounds %>%
            st_bbox() %>%
            st_as_sfc()) +
  geom_sf(fill = NA,
          data=jer_bounds) +
  facet_wrap(~date,
             ncol=4) +
  scale_fill_gradientn(colors = rev(terrain.colors(8)),
                       na.value = 'white') +
  theme_few(base_size = 8) +
  theme(legend.position = c(0.875,0.25),
        axis.text = element_text(size = 4)) +
  ylab(NULL) +
  xlab(NULL)
```


```{r step4b}
#  Prepare point query
q_str <- paste0(gcdl_url,
                points_ep,
                '?',
                paste0(
                  'date_start=',start_date,
                  '&date_end=',end_date,
                  '&crs=',jer_crs,
                  '&datasets=',URLencode(dv_str, reserved = TRUE),
                  '&points=',URLencode(pts_str, reserved = TRUE)))  

outpath <- 'assets/tmp'
out_z <- paste0(outpath,'.zip')

start_clock <- Sys.time()
download.file(q_str, out_z)
end_clock <- Sys.time()

# How long did the download take?
end_clock - start_clock

unzip(out_z)
```

```{r step5b, message=FALSE, warning=FALSE, out.width="100%"}
# Create a raster stack of returned GeoTIFFs
NDVI_2008_pts <- list.files('.','.csv',full.names = TRUE) %>%
  sapply(list) %>%
  map_dfr(read_csv, .id='filename') %>%
  mutate(date = as.Date(str_extract(filename,'\\d{4}-\\d{2}-\\d{2}'))) %>%
  rename(NDVI = value)

NDVI_2008_pts %>%
  ggplot(aes(date,NDVI)) +
  geom_line(aes(group=paste(x,y)),
            color = "gray50",
            size = 0.25) +
  geom_point(aes(color=NDVI),
             size = 2) + 
  scale_color_gradientn(colors = rev(terrain.colors(8)),
                       na.value = 'white') +
  theme_few(base_size = 8) +
  theme(legend.position = c(0.1,0.8)) 
```





